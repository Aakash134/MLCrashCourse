{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLCrashCouse.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "Skm2LbRDCJYH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#ML Crash Course\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "vVhJcZb7Cr-w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Definations:-\n",
        " \n",
        "\n",
        "# 1.   Lable:- \n",
        ">A label is the thing we're predicting. Say name of the image.\n",
        "\n",
        "#2. Features:-\n",
        ">A feature is an input variableâ€”the x variable in simple linear regression. A simple machine learning project might use a single feature, while a more sophisticated machine learning project could use millions of features, specified as: namely:- x1,x2,x3,......xN ( n features.)\n",
        "\n",
        ">In the spam detector example, the features could include the following:\n",
        "\n",
        ">*   words in the email text\n",
        ">*   sender's address\n",
        ">*   time of day the email was sent\n",
        ">*   email contains the phrase \"one weird trick.\"\n",
        "\n",
        "#Models:-\n",
        ">A model defines the relationship between features and label. For example, a spam detection model might associate certain features strongly with \"spam\". Let's highlight two phases of a model's life:\n",
        ">* **Training** means creating or **learning** the model. That is, you show the model labeled examples and enable the model to gradually learn the relationships between features and label.\n",
        ">* **Inference** means applying the trained model to unlabeled examples. That is, you use the trained model to make useful predictions (y'). For example, during inference, you can predict medianHouseValue for new unlabeled examples.\n",
        "\n",
        "#Regression vs. classification :-\n",
        ">A **regression** model predicts continuous values. For example, regression models make predictions that answer questions like the following:\n",
        "\n",
        ">* What is the value of a house in California?\n",
        "\n",
        ">* What is the probability that a user will click on this ad?\n",
        "\n",
        ">A **classification** model predicts discrete values. For example, classification models make predictions that answer questions like the following:\n",
        "\n",
        ">* Is a given email message spam or not spam?\n",
        "\n",
        ">* Is this an image of a dog, a cat, or a hamster?"
      ]
    },
    {
      "metadata": {
        "id": "S5vuA4lXCCG5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}